{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Useful links:\n",
        "\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "\n",
        "- 40 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n",
        "- 20 points - Evaluate on Github Typo Corpus (for masters only)\n",
        "\n",
        "Remarks:\n",
        "\n",
        "- Use Python 3 or greater\n",
        "- Max is 80 points for bachelors, 100 points for masters\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html).\n",
        "\n",
        "[N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf)\n",
        "\n",
        "You may also wnat to implement:\n",
        "\n",
        "- spell-checking for a concrete language - Russian, Tatar, Ukranian, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvigâ€™s solution.\n",
        "\n",
        "Important - your project should not be a mere code copy-paste from somewhere. Implement yourself, analyze why it was suggested this way, and think of improvements/customization.\n",
        "\n",
        "Your solution should be able to perform 4 corrections per second (3-5 words in an example) on a typical cpu.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oML-5sJwGRLE"
      },
      "source": [
        "## Justify your decisions\n",
        "\n",
        "In your implementation you will need to decide which ngram dataset to use, which weights to assign for edit1, edit2 or absent words probabilities, beam search parameters and etc. Write down justificaitons for these choices.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## My solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "class MySolution:\n",
        "    \"\"\"\n",
        "        I will implement all the functions needed for my solution in this class.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ngram_file):\n",
        "        self.ngram_file = ngram_file\n",
        "        self.calc_words()\n",
        "        self.conditional_probs = self.calc_conditional_probs()\n",
        "        self.conditional_probs_weight = 0.9352175845886633\n",
        "        self.frequency_weight = 0.03328620660509829\n",
        "        self.edit_distance_weight = 0.8554663627569048\n",
        "\n",
        "    def calc_conditional_probs(self):\n",
        "        '''\n",
        "            To calculate the conditional probability from the ngram model\n",
        "        '''\n",
        "        conditional_probs = {}\n",
        "        for two_words, count_w1_w2 in self.w1_w2_counter.items():\n",
        "            w1, _ = two_words.split('_')\n",
        "            conditional_probs[two_words] = int(\n",
        "                count_w1_w2) / self.w1_counter[w1]\n",
        "        return conditional_probs\n",
        "\n",
        "    def calc_words(self):\n",
        "        '''\n",
        "            Collecting the information needed to build the ngram model\n",
        "        '''\n",
        "        self.words = []\n",
        "        self.w1_w2_counter = {}\n",
        "        self.w1_counter = {}\n",
        "        with open(self.ngram_file, 'r', encoding='latin-1') as f:\n",
        "            for line in f.readlines():\n",
        "                count, w1, w2 = line.split()\n",
        "                self.w1_w2_counter[w1+'_'+w2] = count\n",
        "                if self.w1_counter.get(w1):\n",
        "                    self.w1_counter[w1] += int(count)\n",
        "                else:\n",
        "                    self.w1_counter[w1] = int(count)\n",
        "                self.words.append(w1)\n",
        "                self.words.append(w2)\n",
        "        self.words = Counter(self.words)\n",
        "\n",
        "    def edit_distance(self, word1, word2):\n",
        "        \"\"\"Calculate the Levenshtein distance between two words.\"\"\"\n",
        "        if len(word1) < len(word2):\n",
        "            return self.edit_distance(word2, word1)\n",
        "\n",
        "        if not word2:\n",
        "            return len(word1)\n",
        "\n",
        "        previous_row = range(len(word2) + 1)\n",
        "\n",
        "        for i, c1 in enumerate(word1):\n",
        "            current_row = [i + 1]\n",
        "\n",
        "            for j, c2 in enumerate(word2):\n",
        "                insertions = previous_row[j + 1] + 1\n",
        "                deletions = current_row[j] + 1\n",
        "                substitutions = previous_row[j] + (c1 != c2)\n",
        "                current_row.append(min(insertions, deletions, substitutions))\n",
        "\n",
        "            previous_row = current_row\n",
        "        if previous_row[-1] != 0:\n",
        "            return previous_row[-1]\n",
        "        return 1\n",
        "\n",
        "    def edits1(self, word):\n",
        "        \"All edits that are one edit away from `word`.\"\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "    def edits2(self, word): return (e2 for e1 in self.edits1(word)\n",
        "                                    for e2 in self.edits1(e1))\n",
        "\n",
        "    def known(self, words): return set(w for w in words if w in self.words)\n",
        "\n",
        "    def candidates(self, word):\n",
        "        '''\n",
        "            Getting all the candidate words that can be the correction of word\n",
        "        '''\n",
        "        if len(word) == 1:\n",
        "            return word\n",
        "        l = []\n",
        "        l.extend(self.known(self.edits1(word)))\n",
        "        if len(word) > 4:\n",
        "            l.extend(self.known(self.edits2(word)))\n",
        "        l.append(word)\n",
        "        return l\n",
        "\n",
        "    def get_best_word(self, original_word, cands, next_word=None, previous_word=None):\n",
        "        '''\n",
        "            Choosing the best word from the candidates list\n",
        "        '''\n",
        "        best_word = None\n",
        "        best_score = 0\n",
        "\n",
        "        if next_word or previous_word:\n",
        "            for word in cands:\n",
        "                gram_format = f'{word}_{next_word}' if next_word else f'{previous_word}_{word}'\n",
        "                if self.conditional_probs.get(gram_format):\n",
        "                    score = self.frequency_weight * self.words[word]/len(self.words) + \\\n",
        "                        self.edit_distance_weight * (1/self.edit_distance(word, original_word)) + \\\n",
        "                        self.conditional_probs_weight * \\\n",
        "                        self.conditional_probs[gram_format]\n",
        "\n",
        "                    if word == original_word and self.known([word]):\n",
        "                        score += 0.1\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_word = word\n",
        "\n",
        "        if best_word == None:\n",
        "            # choose the most frequent candidate with the least edit distance\n",
        "            for word in cands:\n",
        "                if self.words[word] > 0:\n",
        "                    score = 0.8 * self.words[word]/len(self.words) + \\\n",
        "                        0.2 * 1/(self.edit_distance(word, original_word))\n",
        "                    if word == original_word and self.known([word]):\n",
        "                        score += 0.1\n",
        "                    if score > best_score:\n",
        "                        best_word = word\n",
        "                        best_score = score\n",
        "        if best_word == None:\n",
        "            return original_word\n",
        "        return best_word\n",
        "\n",
        "    def check(self, sentence):\n",
        "        '''\n",
        "            This function takes the sentence as an input and return the same sentence corrected\n",
        "        '''\n",
        "        result = []\n",
        "        # correcting the first word\n",
        "        first_word = sentence[0]\n",
        "        if len(sentence) > 1:\n",
        "            if self.words[first_word] <= 50:  # mean that this word need correction\n",
        "                next_word = sentence[1]\n",
        "                cands = self.candidates(first_word)\n",
        "                best_word = self.get_best_word(first_word, cands, next_word)\n",
        "                result.append(best_word)\n",
        "            else:\n",
        "                result.append(first_word)\n",
        "        else:\n",
        "            cands = self.candidates(first_word)\n",
        "            return self.get_best_word(first_word, cands)\n",
        "\n",
        "        # correcting the rest of the sentence\n",
        "        for i in range(1, len(sentence)):\n",
        "            # if the word frequency is less than 50, then it is probably misspelled\n",
        "            if self.words[sentence[i]] <= 50:\n",
        "                cands = self.candidates(sentence[i])\n",
        "                previous_word = result[i-1]\n",
        "                best_word = self.get_best_word(\n",
        "                    sentence[i], cands, previous_word=previous_word)\n",
        "                result.append(best_word)\n",
        "            else:\n",
        "                result.append(sentence[i])\n",
        "        return result\n",
        "\n",
        "\n",
        "my_solution = MySolution('w2_.txt')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What are the problems with Norvig's solution?\n",
        "\n",
        "- His solution is not able to correct unknown words\n",
        "- His error model is trivial: the smaller the edit distance, the smaller the error.\n",
        "- His solution can not look at the context of the word\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## My proposed solution to this problems\n",
        "\n",
        "First of all, the dataset which Norvig's solution was trained on is small and it doesn't contain variaty of words, so in my solution the corpus of words that I used is from the ngram data file which contain large amount of words in different shapes. This limits the number of the unknown words that the model faces.\n",
        "\n",
        "Secondly, his error model was prioritizing the candidates with small edit distance. However, that is not always the case as. So to make the model more flexable, I allowed the candidates to be a list of all 1 and 2 edits words plus the original word. This solution rely on the fact that the model will make the right decision and choose the suitable word for the given context.\n",
        "\n",
        "Finally, his solution can not look at the context of the word which increase the probability of making errors while choosing from the candidates. To solve this problem, I used bigram model to look at the context of the word and propose the correction with the highest conditional probability, highest frequenct, and lowest edit distance score in a weighted manner.\n",
        "\n",
        "### Why did I choose bigram model?\n",
        "\n",
        "- Bigram models are faster and require less memory than 5-gram models because they consider pairs of adjacent words rather than groups of five words at a time.\n",
        "- In a bigram model, the probability of a word depends only on the preceding word, so it can handle unseen words better than a 5-gram model, which would require seeing the preceding four words to make a prediction.\n",
        "- Simplicity and ease of implementation\n",
        "\n",
        "### Why did I choose these specific weights for the scores of the candidates?\n",
        "\n",
        "- my_solution.conditional_probs_weight = 0.9352175845886633\n",
        "- my_solution.frequency_weight = 0.03328620660509829\n",
        "- my_solution.edit_distance_weight = 0.8554663627569048\n",
        "\n",
        "Using trial and error on the training dataset, I came to a conclusion that these are the most suitable weights to use.\n",
        "\n",
        "I assigned these values randomly for 50 trials and took the best preforming weights on the training set and then reported their results on the validation set\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating my own dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "\n",
        "y = []\n",
        "with open(r'datasets\\articles.txt', 'r') as f:  # a collection of articles\n",
        "    y = [words(line.strip('\\n')) for line in f.readlines()]\n",
        "\n",
        "training_y = y[:int(len(y)*0.8)]\n",
        "with open(r'datasets\\training_y.txt', 'a') as f:\n",
        "    for line in training_y:\n",
        "        f.write(' '.join(line) + '\\n')\n",
        "\n",
        "validation_y = y[int(len(y)*0.8):]\n",
        "with open(r'datasets\\validation_y.txt', 'a') as f:\n",
        "    for line in validation_y:\n",
        "        f.write(' '.join(line) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def misspell_word(word, noise_prob):\n",
        "    \"\"\"Misspells a given word with a given noise probability.\"\"\"\n",
        "    if random.uniform(0, 1) <= noise_prob:\n",
        "        # Choose a random letter to replace\n",
        "        index = random.randint(0, len(word) - 1)\n",
        "        new_char = chr(random.randint(ord('a'), ord('z')))\n",
        "        return word[:index] + new_char + word[index + 1:]\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "\n",
        "def misspell_text(text, noise_prob):\n",
        "    \"\"\"Misspells all the words in a given text with a given noise probability.\"\"\"\n",
        "    result = []\n",
        "    for sentence in text:\n",
        "        misspelled_sentece = [misspell_word(\n",
        "            word, noise_prob) for word in sentence.split]\n",
        "        result.append(misspelled_sentece)\n",
        "    return result\n",
        "\n",
        "\n",
        "# Generate a misspelled version of the text with a given noise probability\n",
        "noise_prob = 0.5\n",
        "training_x = misspell_text(training_y, noise_prob)\n",
        "validation_x = misspell_text(validation_y, noise_prob)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, x, y):\n",
        "    total_words = 0\n",
        "    my_correct = 0\n",
        "    for i, sentence in enumerate(x):\n",
        "        if len(sentence):\n",
        "            result = model.check(sentence)\n",
        "            for j in range(len(sentence)):\n",
        "                if result[j] == y[i][j]:\n",
        "                    my_correct += 1\n",
        "                total_words += 1\n",
        "    return my_correct/total_words\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I carry out the trails that I mentioned earlier to find which weights are the most suitable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1\n",
            "0.8316008316008316\n",
            "(0.8866385785933448, 0.5426769478432463, 0.2997161569521408)\n",
            "Trial 2\n",
            "0.8316008316008316\n",
            "(0.9514580737088721, 0.9175060857503533, 0.8612165274009033)\n",
            "Trial 3\n",
            "0.8295218295218295\n",
            "(0.1851382537582692, 0.2996027160810769, 0.28515713507481155)\n",
            "Trial 4\n",
            "0.8316008316008316\n",
            "(0.9534656165705472, 0.9675053070791463, 0.5581648301554646)\n",
            "Trial 5\n",
            "0.8295218295218295\n",
            "(0.17889009631087016, 0.4603203375140825, 0.14740059281681372)\n",
            "Trial 6\n",
            "0.8357588357588358\n",
            "(0.42335956436369326, 0.2490727496466537, 0.8449369489075931)\n",
            "Trial 7\n",
            "0.8316008316008316\n",
            "(0.5977778294057307, 0.7076233553841301, 0.2919550152153986)\n",
            "Trial 8\n",
            "0.8305613305613305\n",
            "(0.09462556453806403, 0.4544999058014326, 0.9254127649797096)\n",
            "Trial 9\n",
            "0.8357588357588358\n",
            "(0.4705326604848764, 0.1822928371615714, 0.8475318967377594)\n",
            "Trial 10\n",
            "0.8232848232848233\n",
            "(0.21740419746182948, 0.5409155846453342, 0.024890286065343936)\n",
            "Trial 11\n",
            "0.8295218295218295\n",
            "(0.5518473477426818, 0.8663907895925044, 0.6850918714303492)\n",
            "Trial 12\n",
            "0.8367983367983368\n",
            "(0.6231286888890727, 0.06081291476321904, 0.5191712361954182)\n",
            "Trial 13\n",
            "0.8326403326403327\n",
            "(0.8817444072734179, 0.6181042044149003, 0.5424005683022943)\n",
            "Trial 14\n",
            "0.8347193347193347\n",
            "(0.8665500196078321, 0.3094431437906029, 0.9930110598239609)\n",
            "Trial 15\n",
            "0.8295218295218295\n",
            "(0.19328611765748016, 0.8844613007947894, 0.469473916743105)\n",
            "Trial 16\n",
            "0.8336798336798337\n",
            "(0.8078592853089404, 0.134157310692941, 0.4451915602461578)\n",
            "Trial 17\n",
            "0.8347193347193347\n",
            "(0.38576059541085483, 0.297349958745872, 0.8918006294842687)\n",
            "Trial 18\n",
            "0.8326403326403327\n",
            "(0.7311325832194205, 0.07908628952945795, 0.06911264518017779)\n",
            "Trial 19\n",
            "0.8316008316008316\n",
            "(0.5110428231669033, 0.6009982474124685, 0.345885984858736)\n",
            "Trial 20\n",
            "0.8326403326403327\n",
            "(0.692367558136701, 0.4617629478231001, 0.6325260843831514)\n",
            "Trial 21\n",
            "0.8367983367983368\n",
            "(0.12665555062808298, 0.05608553701429797, 0.5242323178269811)\n",
            "Trial 22\n",
            "0.8295218295218295\n",
            "(0.7970138507225939, 0.5699424630133187, 0.04438813062154057)\n",
            "Trial 23\n",
            "0.8347193347193347\n",
            "(0.7649183629082689, 0.09384872079217332, 0.8151336745597255)\n",
            "Trial 24\n",
            "0.8336798336798337\n",
            "(0.5422466213473748, 0.5894455248729389, 0.978951232370437)\n",
            "Trial 25\n",
            "0.8295218295218295\n",
            "(0.40056132810177425, 0.7820313077617821, 0.27533333603873755)\n",
            "Trial 26\n",
            "0.8274428274428275\n",
            "(0.12381919306871325, 0.46255421607630176, 0.17755254781021135)\n",
            "Trial 27\n",
            "0.8326403326403327\n",
            "(0.07369298594654938, 0.1601689508831401, 0.3393529297421033)\n",
            "Trial 28\n",
            "0.8326403326403327\n",
            "(0.2304979821097184, 0.5674922771685835, 0.9585680493994292)\n",
            "Trial 29\n",
            "0.8316008316008316\n",
            "(0.8032086549649838, 0.5175112381808422, 0.24810994871255743)\n",
            "Trial 30\n",
            "0.8305613305613305\n",
            "(0.08820756440999056, 0.4446902086520208, 0.843724536335604)\n",
            "Trial 31\n",
            "0.8336798336798337\n",
            "(0.5172101262623015, 0.27451213499362415, 0.5403896130064416)\n",
            "Trial 32\n",
            "0.8316008316008316\n",
            "(0.9102219904893709, 0.8870046347205847, 0.8433060811991014)\n",
            "Trial 33\n",
            "0.8326403326403327\n",
            "(0.992747944892018, 0.6957749150548086, 0.7287870225496201)\n",
            "Trial 34\n",
            "0.8305613305613305\n",
            "(0.7455534921662057, 0.7556502264714697, 0.08637912558663308)\n",
            "Trial 35\n",
            "0.8284823284823285\n",
            "(0.07878067392749821, 0.9910109454922537, 0.2588239982205309)\n",
            "Trial 36\n",
            "0.8316008316008316\n",
            "(0.6914432358967209, 0.611585754129706, 0.42147311432253165)\n",
            "Trial 37\n",
            "0.8316008316008316\n",
            "(0.48614267442762904, 0.40535149714639596, 0.2816347426991904)\n",
            "Trial 38\n",
            "0.840956340956341\n",
            "(0.9352175845886633, 0.03328620660509829, 0.8554663627569048)\n",
            "Trial 39\n",
            "0.8367983367983368\n",
            "(0.6017313868041597, 0.010241677550624884, 0.7239934291652614)\n",
            "Trial 40\n",
            "0.8264033264033264\n",
            "(0.18563657196608452, 0.7969336689792234, 0.11960893306883635)\n",
            "Trial 41\n",
            "0.8295218295218295\n",
            "(0.31107179513454297, 0.6148807644051459, 0.26167846984332976)\n",
            "Trial 42\n",
            "0.83991683991684\n",
            "(0.6576156593232682, 0.029767453204149974, 0.7201531244936848)\n",
            "Trial 43\n",
            "0.8357588357588358\n",
            "(0.6926263010143355, 0.18563331501258584, 0.7127290828824862)\n",
            "Trial 44\n",
            "0.8305613305613305\n",
            "(0.8877194859327772, 0.9844638016410956, 0.16152188654772404)\n",
            "Trial 45\n",
            "0.8274428274428275\n",
            "(0.23256545014396768, 0.889392580361729, 0.19323639397795866)\n",
            "Trial 46\n",
            "0.8347193347193347\n",
            "(0.8088358381226163, 0.26326227060854823, 0.8544884735177743)\n",
            "Trial 47\n",
            "0.8274428274428275\n",
            "(0.052827751037329396, 0.5048179582673462, 0.09610518328917694)\n",
            "Trial 48\n",
            "0.8305613305613305\n",
            "(0.8058805957271783, 0.8123877390425585, 0.14519621995766918)\n",
            "Trial 49\n",
            "0.8336798336798337\n",
            "(0.8084232168392514, 0.16397597211867598, 0.07330986163725406)\n",
            "Trial 50\n",
            "0.8284823284823285\n",
            "(0.06801068768141938, 0.7652776224790292, 0.27957913724965755)\n",
            "0.840956340956341\n",
            "(0.9352175845886633, 0.03328620660509829, 0.8554663627569048)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "max_accuracy = 0\n",
        "weights = ()\n",
        "for i in range(50):\n",
        "    print(f'Trial {i+1}')\n",
        "    my_solution = MySolution('w2_.txt')\n",
        "    my_solution.conditional_probs_weight = random.random()\n",
        "    my_solution.frequency_weight = random.random()\n",
        "    my_solution.edit_distance_weight = random.random()\n",
        "    acc = evaluate(my_solution, training_x[:100], training_y[:100])\n",
        "    if acc > max_accuracy:\n",
        "        max_accuracy = acc\n",
        "        weights = (my_solution.conditional_probs_weight,\n",
        "                   my_solution.frequency_weight, my_solution.edit_distance_weight)\n",
        "    print(acc)\n",
        "    print((my_solution.conditional_probs_weight,\n",
        "          my_solution.frequency_weight, my_solution.edit_distance_weight))\n",
        "print(max_accuracy)\n",
        "print(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.840956340956341\n",
            "(0.9352175845886633, 0.03328620660509829, 0.8554663627569048)\n"
          ]
        }
      ],
      "source": [
        "print(max_accuracy)\n",
        "print(weights)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Norvig's solution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['value']"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "\n",
        "WORDS = Counter(words(open('big.txt').read()))\n",
        "\n",
        "\n",
        "def P(word, N=sum(WORDS.values())):\n",
        "    \"Probability of `word`.\"\n",
        "    return WORDS[word] / N\n",
        "\n",
        "\n",
        "def correction(sentence):\n",
        "    \"Most probable spelling correction for word.\"\n",
        "    result = []\n",
        "    for word in sentence:\n",
        "        result.append(max(candidates(word), key=P))\n",
        "    return result\n",
        "\n",
        "\n",
        "def candidates(word):\n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "\n",
        "def known(words):\n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "\n",
        "\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes = [L + R[1:] for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "    inserts = [L + c + R for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "\n",
        "def edits2(word):\n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "\n",
        "\n",
        "correction(['value'])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing both solutions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'unit_tests pass'"
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_solution = MySolution('w2_.txt')\n",
        "\n",
        "\n",
        "def correction(word):\n",
        "    return my_solution.check([word])\n",
        "\n",
        "\n",
        "def unit_tests():\n",
        "    assert correction('speling') == 'spelling'              # insert\n",
        "    assert correction('korrectud') == 'corrected'           # replace 2\n",
        "    assert correction('bycycle') == 'bicycle'               # replace\n",
        "    assert correction('inconvient') == 'inconvenient'       # insert 2\n",
        "    assert correction('arrainged') == 'arranged'            # delete\n",
        "    # transpose + delete\n",
        "    assert correction('peotryy') == 'poetry'\n",
        "    assert correction('word') == 'word'                     # known\n",
        "    assert correction('quintessential') == 'quintessential'  # unknown\n",
        "    assert words('This is a TEST.') == ['this', 'is', 'a', 'test']\n",
        "    assert Counter(words('This is a test. 123; A TEST this is.')) == (\n",
        "        Counter({'123': 1, 'a': 2, 'is': 2, 'test': 2, 'this': 2}))\n",
        "    return 'unit_tests pass'\n",
        "\n",
        "\n",
        "unit_tests()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I wrote a paragraph about philosophy and added some misspelled words to it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My solution got 97.43589743589743% at 54.956868808326085 words per second\n",
            "Norvig solution got 94.01709401709401%\n"
          ]
        }
      ],
      "source": [
        "# loading the dataset\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "\n",
        "misspelled = 'p1_misspelled.txt'\n",
        "correct = 'p1.txt'\n",
        "x = []\n",
        "with open(misspelled, 'r') as f:\n",
        "    x = [words(line.strip('\\n')) for line in f.readlines()]\n",
        "\n",
        "y = []\n",
        "with open(correct, 'r') as f:\n",
        "    y = [words(line.strip('\\n')) for line in f.readlines()]\n",
        "\n",
        "\n",
        "my_solution = MySolution('w2_.txt')\n",
        "my_solution.conditional_probs_weight = 0.9352175845886633\n",
        "my_solution.frequency_weight = 0.03328620660509829\n",
        "my_solution.edit_distance_weight = 0.8554663627569048\n",
        "\n",
        "total_words = 0\n",
        "my_correct = 0\n",
        "norv_correct = 0\n",
        "wrong = []\n",
        "wrong2 = []\n",
        "start = time.time()\n",
        "for i, sentence in enumerate(x):\n",
        "    my_result = my_solution.check(sentence)\n",
        "    norvig_result = correction(sentence)\n",
        "\n",
        "    for j in range(len(sentence)):\n",
        "        if my_result[j] == y[i][j]:\n",
        "            my_correct += 1\n",
        "        else:\n",
        "            wrong.append((my_result[j], y[i][j], x[i][j], my_result[j-1]))\n",
        "        if norvig_result[j] == y[i][j]:\n",
        "            norv_correct += 1\n",
        "        else:\n",
        "            wrong2.append(norvig_result[j])\n",
        "        total_words += 1\n",
        "dt = time.time() - start\n",
        "print(\n",
        "    f'My solution got {my_correct/total_words*100}% at {total_words/dt} words per second')\n",
        "print(f'Norvig solution got {norv_correct/total_words*100}%')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, my solution preformed better than Norvig solution. For farther work, I suggest using linear regression to assign the weights of the frequency, edit distance, and conditional probability.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VISJtkFD4VhV"
      },
      "source": [
        "## Evaluate on Github Typo Corpus\n",
        "\n",
        "Now, you need to evaluate your solution on the Github Typo Corpus. Don't forget to compare the accuracy with the Norvig's solution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tP9GZCYsWjgB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'gzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https: // github-typo-corpus.s3.amazonaws.com/data/github-typo-corpus.v1.0.0.jsonl.gz\n",
        "!gzip - d github-typo-corpus.v1.0.0.jsonl.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "oiUTzkLNGr2q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size = 245909\n"
          ]
        }
      ],
      "source": [
        "import jsonlines\n",
        "\n",
        "dataset_file = \"github-typo-corpus.v1.0.0.jsonl\"\n",
        "\n",
        "dataset = []\n",
        "other_langs = set()\n",
        "\n",
        "with jsonlines.open(dataset_file) as reader:\n",
        "    for obj in reader:\n",
        "        for edit in obj['edits']:\n",
        "            if edit['src']['lang'] == 'eng' and edit['is_typo']:\n",
        "                src, tgt = edit['src']['text'], edit['tgt']['text']\n",
        "                if src.lower() != tgt.lower():\n",
        "                    dataset.append((src, tgt))\n",
        "\n",
        "print(f\"Dataset size = {len(dataset)}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hjiKaUj0HKYo"
      },
      "source": [
        "Please, explore the dataset. You may see, that this is\n",
        "\n",
        "- mostly markdown\n",
        "- some common mistakes with do/does\n",
        "- some just refer to punctuation typos (which we do not consider)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "gpkAqj6RHOr9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        \"\"\"Make am instance. =>         \"\"\"Make an instance.\n",
            "* travis: test agains Node.js 11 => * travis: test against Node.js 11\n",
            "The parser receive a string and returns an array inside a user-provided  => The parser receives a string and returns an array inside a user-provided \n",
            "CSV data is send through the `write` function and the resulted data is obtained => CSV data is sent through the `write` function and the resulting data is obtained\n",
            "One useful function part of the Stream API is `pipe` to interact between  => One useful function of the Stream API is `pipe` to interact between \n",
            "source to a `stream.Writable` object destination. This example available as  => source to a `stream.Writable` object destination. This example is available as \n",
            "`node samples/pipe.js` read the file, parse its content and transform it. => `node samples/pipe.js` and reads the file, parses its content and transforms it.\n",
            "Most of the generator is imported from its parent project [CSV][csv] in a effort  => Most of the generator is imported from its parent project [CSV][csv] in an effort \n",
            "*   `quote`             Optionnal character surrounding a field, one character only, defaults to double quotes.    => *   `quote`             Optional character surrounding a field, one character only, defaults to double quotes.   \n",
            "The parser receive a string and return an array inside a user-provided  => The parser receive a string and returns an array inside a user-provided \n"
          ]
        }
      ],
      "source": [
        "for pair in dataset[1010:1020]:\n",
        "    print(f\"{pair[0]} => {pair[1]}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8p0kp4G-HexP"
      },
      "source": [
        "Compare your implementation with Norvig's solution on this dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "vy85_6oKHE3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My solution got 79.77807666442501%\n",
            "Norvig solution got 78.0497646267653%\n"
          ]
        }
      ],
      "source": [
        "limit = 10000\n",
        "counter = limit\n",
        "my_solution = MySolution('w2_.txt')\n",
        "total_words = 0\n",
        "my_correct = 0\n",
        "norv_correct = 0\n",
        "wrong = []\n",
        "wrong2 = []\n",
        "try:\n",
        "    for i, (src, target) in enumerate(dataset):\n",
        "        if i == limit:\n",
        "            break\n",
        "        # YOUR CODE HERE\n",
        "        x = words(src)\n",
        "        y = words(target)\n",
        "        my_result = my_solution.check(x)\n",
        "        norvig_result = correction(x)\n",
        "\n",
        "        for j in range(len(x)):\n",
        "            try:\n",
        "                if my_result[j] == y[j]:\n",
        "                    my_correct += 1\n",
        "                else:\n",
        "                    wrong.append((my_result[j], y[j]))\n",
        "                if norvig_result[j] == y[j]:\n",
        "                    norv_correct += 1\n",
        "                else:\n",
        "                    wrong2.append(norvig_result[j])\n",
        "            except:\n",
        "                pass\n",
        "            total_words += 1\n",
        "except:\n",
        "    pass\n",
        "print(f'My solution got {my_correct/total_words*100}%')\n",
        "print(f'Norvig solution got {norv_correct/total_words*100}%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
